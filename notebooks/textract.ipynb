{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "AWS_ACCESS_KEY_ID = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "AWS_SESSION_TOKEN = os.getenv('AWS_SESSION_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "textract = boto3.client('textract', \n",
    "                      region_name='us-east-1',\n",
    "                      aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "                      aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "                      aws_session_token=AWS_SESSION_TOKEN\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = textract.detect_document_text(\n",
    "    Document={\n",
    "        'S3Object': {\n",
    "            'Bucket': 'jf-test-general-bucket',\n",
    "            'Name': 'test-textract/documents/Data Science Resume.pdf'\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response['Blocks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BlockType': 'LINE',\n",
       " 'Confidence': 99.8028793334961,\n",
       " 'Text': 'AWS (Step',\n",
       " 'Geometry': {'BoundingBox': {'Width': 0.07312901318073273,\n",
       "   'Height': 0.012267205864191055,\n",
       "   'Left': 0.5098416805267334,\n",
       "   'Top': 0.23090672492980957},\n",
       "  'Polygon': [{'X': 0.5098416805267334, 'Y': 0.23090672492980957},\n",
       "   {'X': 0.5829640626907349, 'Y': 0.23090963065624237},\n",
       "   {'X': 0.5829706788063049, 'Y': 0.24317392706871033},\n",
       "   {'X': 0.5098479986190796, 'Y': 0.24317088723182678}]},\n",
       " 'Id': '29e0516e-89e9-4942-8b7f-426895faaf7a',\n",
       " 'Relationships': [{'Type': 'CHILD',\n",
       "   'Ids': ['807f9ad1-8a16-4289-8d75-bdaae2d21c3b',\n",
       "    '0a578188-6a7a-4783-964b-f262f496e2e8']}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['Blocks'][16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text = ''\n",
    "\n",
    "for block in response['Blocks']:\n",
    "    if block['BlockType'] == 'LINE':\n",
    "        full_text += block['Text'] + '\\n'\n",
    "\n",
    "full_text = full_text[:-1] # remove last white space character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John Funk\\nData Engineer\\nf'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_text[0:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From the Resume text for a job aspirant below, extract Entities strictly as instructed below\\n1. First, look for the Person Entity type in the text and extract the needed information defined below:\\n`id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. NEVER create new entity types that aren\\'t mentioned below. Document must be summarized and stored inside Person entity under `description` property\\n    Entity Types:\\n    label:\\'Person\\',id:string,role:string,description:string //Person Node\\n2. Description property should be a crisp text summary and MUST NOT be more than 100 characters\\n3. If you cannot find any information on the entities & relationships above, it is okay to return empty value. DO NOT create fictious data\\n4. Do NOT create duplicate entities\\n5. Restrict yourself to extract only Person information. No Position, Company, Education or Skill information should be focussed.\\n6. NEVER Impute missing values\\n7. Respond ONLY with output JSON and nothing else\\n8. Each resume should only contain one person entity\\nExample Output JSON:\\n{\"entities\": [{\"label\":\"Person\",\"id\":\"person1\",\"role\":\"Prompt Developer\",\"description\":\"Prompt Developer with more than 30 years of LLM experience\"}]}\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_prompt_system = \"\"\"From the Resume text for a job aspirant below, extract Entities strictly as instructed below\n",
    "1. First, look for the Person Entity type in the text and extract the needed information defined below:\n",
    "`id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring to this property to define the relationship between entities. NEVER create new entity types that aren't mentioned below. Document must be summarized and stored inside the Person entity under `description` property\n",
    "    Entity Types:\n",
    "    label:'Person',id:string,role:string,description:string //Person Node\n",
    "2. Description property should be a crisp text summary and MUST NOT be more than 100 characters\n",
    "3. If you cannot find any information on the entities & relationships above, it is okay to return empty value. DO NOT create fictitious data\n",
    "4. Do NOT create duplicate entities\n",
    "5. Restrict yourself to extract only Person information. No Position, Company, Education or Skill information should be focussed.\n",
    "6. NEVER Impute missing values\n",
    "7. Respond ONLY with output JSON and nothing else\n",
    "8. Each resume should only contain one person entity\n",
    "Example Output JSON:\n",
    "{\"entities\": [{\"label\":\"Person\",\"id\":\"person1\",\"role\":\"Prompt Developer\",\"description\":\"Prompt Developer with more than 30 years of LLM experience\"}]}\n",
    "\"\"\"\n",
    "\n",
    "person_prompt_user= \"\"\"Question: Now, extract the Person for the text below -\n",
    "\"\"\"\n",
    "\n",
    "person_prompt_user += full_text\n",
    "person_prompt_user += \"\"\"\n",
    "Answer\n",
    "\"\"\"\n",
    "person_prompt_system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo-16k\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": person_prompt_system},\n",
    "    {\"role\": \"user\", \"content\": person_prompt_user}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'Person',\n",
       "  'id': 'person1',\n",
       "  'role': 'Data Engineer',\n",
       "  'description': 'Data Engineer at Travelers Insurance with experience in developing streaming data processing pipeline using pySpark for ingesting real-time policy data into a graph structure in Neo4j, developing a POC for a Feature Store solution and machine learning feature engineering pipeline for Data Scientists, and developing an aerial image processing pipeline for ingestion into solar roof classification models'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(completion.choices[0].message['content'])['entities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
